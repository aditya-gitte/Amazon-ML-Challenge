{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yake\n",
    "import re\n",
    "import threading\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset, enter the path of the csv file in the csv_file_name variable\n",
    "csv_file_name=\"dataset/train.csv\"\n",
    "sum_df = pd.read_csv(csv_file_name)\n",
    "sum_df['NUMERIC_DATA'] = ''\n",
    "sum_df=sum_df.dropna()\n",
    "# sum_df=sum_df.sample(n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_keywords(text):\n",
    "def getKeywordsUsingYake(text):\n",
    "\n",
    "    # Create a YAKE keyword extractor\n",
    "    kw_extractor = yake.KeywordExtractor(lan=\"en\", n=1, dedupLim=0.9, top=20)\n",
    "\n",
    "    # Extract keywords from the text\n",
    "    keywords = kw_extractor.extract_keywords(text)\n",
    "\n",
    "    # Join keywords into a comma-separated string\n",
    "    keyword_string = \", \".join([keyword[0] for keyword in keywords])\n",
    "\n",
    "    return keyword_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getKeywordsUsingRake(text, stop_words):\n",
    "    # # Tokenize text and remove stop words\n",
    "    # tokens = word_tokenize(text)\n",
    "    # # stop_words = set(stopwords.words('english'))\n",
    "    # filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "\n",
    "    # # Stem tokens\n",
    "    # stemmer = PorterStemmer()\n",
    "    # stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "\n",
    "    # # Calculate word scores using RAKE algorithm\n",
    "    # word_scores = {}\n",
    "    # for token in stemmed_tokens:\n",
    "    #     if token not in word_scores:\n",
    "    #         word_scores[token] = 0\n",
    "    #     word_scores[token] += 1\n",
    "\n",
    "    # for token in word_scores:\n",
    "    #     word_scores[token] /= float(len(stemmed_tokens))\n",
    "\n",
    "    # # Sort words by score and extract top 20\n",
    "    # sorted_words = sorted(word_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    # keywords = [word[0] for word in sorted_words[:20]]\n",
    "\n",
    "    # #removing the special character, emojis, and punctuation\n",
    "\n",
    "    # opstr = ', '.join(keywords)\n",
    "    # return opstr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKeywordsUsingRake(text, stop_words):\n",
    "    # Tokenize text and remove stop words\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "\n",
    "    # Calculate word scores using RAKE algorithm\n",
    "    word_scores = {}\n",
    "    for token in filtered_tokens:\n",
    "        if token not in word_scores:\n",
    "            word_scores[token] = 0\n",
    "        word_scores[token] += 1\n",
    "\n",
    "    for token in word_scores:\n",
    "        word_scores[token] /= float(len(filtered_tokens))\n",
    "\n",
    "    # Sort words by score and extract top 20\n",
    "    sorted_words = sorted(word_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Remove stopwords and special characters\n",
    "    new_list = []\n",
    "\n",
    "    # Loop through each item in the original list\n",
    "    for item in sorted_words:\n",
    "        # Check if the item contains only alphanumeric characters\n",
    "        if len(item[0])==1:\n",
    "            continue\n",
    "        if item[0].isalnum():\n",
    "            # If the item contains only alphanumeric characters, add it to the new list\n",
    "            new_list.append(item[0])\n",
    "    keywords = [word for word in new_list[:30]]\n",
    "    opstr = ', '.join(keywords)\n",
    "    return opstr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_data_extractor(description):\n",
    "    \n",
    "\n",
    "    length_pattern = r\"\\b(?:\\d+(?:\\s\\d+/\\d+)?(?:\\.\\d+)?|\\d+/\\d+)(?:\\s*\\*\\s*(?:\\d+(?:\\s\\d+/\\d+)?(?:\\.\\d+)?|\\d+/\\d+))*\\s*(?:cm|mm|m|in(?:ch(?:es)?)?|ft|foot|feet|yd|yard|')?\\b\"\n",
    "\n",
    "\n",
    "    lengths = re.findall(length_pattern, description, re.IGNORECASE)\n",
    "\n",
    "    \n",
    "\n",
    "    opstr=\"\"\n",
    "    for i in lengths:\n",
    "        opstr=opstr+i+\",\"\n",
    "    \n",
    "    return opstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the column name\n",
    "column_name_1 = \"TITLE\"\n",
    "column_name_2 = \"BULLET_POINTS\"\n",
    "column_name_3 = \"DESCRIPTION\"\n",
    "\n",
    "# Loop through each row in the dataframe\n",
    "for index, row in sum_df.iterrows():\n",
    "    # Extract the text to be summarized from the column\n",
    "    text_1 = row[column_name_1]\n",
    "    text_2 = row[column_name_2]\n",
    "    text_3 = row[column_name_3]\n",
    "\n",
    "    inpstr= text_1+\" \"+text_2+\" \"+text_3\n",
    "    \n",
    "    # Use get numeric data\n",
    "    ndata=numeric_data_extractor(inpstr)\n",
    "\n",
    "    # Replace the original text with the summary in the same column\n",
    "    sum_df.at[index, 'NUMERIC_DATA'] = ndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that runs code block 1\n",
    "def process_column_1():\n",
    "    # Set the column name\n",
    "    column_name = \"BULLET_POINTS\"\n",
    "\n",
    "    # Loop through each row in the dataframe\n",
    "    for index, row in sum_df.iterrows():\n",
    "        # Extract the text to be summarized from the column\n",
    "        text = row[column_name]\n",
    "\n",
    "        # Use yake to extract 20 keywords \n",
    "        kw = getKeywordsUsingRake(text,stop_words)\n",
    "\n",
    "        # Replace the original text with the summary in the same column\n",
    "        sum_df.at[index, column_name] = kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that runs code block 2\n",
    "def process_column_2():\n",
    "    # Set the column name\n",
    "    column_name = \"DESCRIPTION\"\n",
    "\n",
    "    # Loop through each row in the dataframe\n",
    "    for index, row in sum_df.iterrows():\n",
    "        # Extract the text to be summarized from the column\n",
    "        text = row[column_name]\n",
    "\n",
    "        # Use yake to extract 20 keywords \n",
    "        kw = getKeywordsUsingRake(text,stop_words)\n",
    "\n",
    "        # Replace the original text with the summary in the same column\n",
    "        sum_df.at[index, column_name] = kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manages threads so that the first and second code block run simultaneously\n",
    "\n",
    "\n",
    "# Create two threads, one for each code block\n",
    "t1 = threading.Thread(target=process_column_1)\n",
    "t2 = threading.Thread(target=process_column_2)\n",
    "\n",
    "# Start both threads\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "# Wait for both threads to finish\n",
    "t1.join()\n",
    "t2.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>BULLET_POINTS</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>PRODUCT_TYPE_ID</th>\n",
       "      <th>PRODUCT_LENGTH</th>\n",
       "      <th>NUMERIC_DATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2765088</td>\n",
       "      <td>PRIKNIK Horn Red Electric Air Horn Compressor ...</td>\n",
       "      <td>Compatible, SX4, Horn, High, Loud, Dual, Tone,...</td>\n",
       "      <td>Voltage, Material, 12V, dB, Pump, Dual, Tone, ...</td>\n",
       "      <td>7537</td>\n",
       "      <td>748.031495</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1594019</td>\n",
       "      <td>ALISHAH Women's Cotton Ankle Length Leggings C...</td>\n",
       "      <td>fabric, Made, 95, cotton, Lycra, gives, ways, ...</td>\n",
       "      <td>inch, Ankel, Leggings, Length, 30, 32, 34, col...</td>\n",
       "      <td>2996</td>\n",
       "      <td>787.401574</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2152929</td>\n",
       "      <td>HINS Metal Bucket Shape Plant Pot for Indoor &amp;...</td>\n",
       "      <td>plants, indoor, stand, plant, Simple, elegant,...</td>\n",
       "      <td>HINS, Pot, one, choice, plants, take, color, r...</td>\n",
       "      <td>5725</td>\n",
       "      <td>950.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2026580</td>\n",
       "      <td>Delavala Self Adhesive Kitchen Backsplash Wall...</td>\n",
       "      <td>kitchen, PVC, aluminum, foil, made, plastic, m...</td>\n",
       "      <td>br, nbsp, strong, kitchen, Aluminum, Foil, tim...</td>\n",
       "      <td>6030</td>\n",
       "      <td>984.251967</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2998633</td>\n",
       "      <td>Hexwell Essential oil for Home Fragrance Oil A...</td>\n",
       "      <td>Oil, essential, Essential, oils, oil, could, u...</td>\n",
       "      <td>oils, Transform, home, workplace, hotel, room,...</td>\n",
       "      <td>8201</td>\n",
       "      <td>393.700787</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRODUCT_ID                                              TITLE  \\\n",
       "2     2765088  PRIKNIK Horn Red Electric Air Horn Compressor ...   \n",
       "3     1594019  ALISHAH Women's Cotton Ankle Length Leggings C...   \n",
       "5     2152929  HINS Metal Bucket Shape Plant Pot for Indoor &...   \n",
       "7     2026580  Delavala Self Adhesive Kitchen Backsplash Wall...   \n",
       "9     2998633  Hexwell Essential oil for Home Fragrance Oil A...   \n",
       "\n",
       "                                       BULLET_POINTS  \\\n",
       "2  Compatible, SX4, Horn, High, Loud, Dual, Tone,...   \n",
       "3  fabric, Made, 95, cotton, Lycra, gives, ways, ...   \n",
       "5  plants, indoor, stand, plant, Simple, elegant,...   \n",
       "7  kitchen, PVC, aluminum, foil, made, plastic, m...   \n",
       "9  Oil, essential, Essential, oils, oil, could, u...   \n",
       "\n",
       "                                         DESCRIPTION  PRODUCT_TYPE_ID  \\\n",
       "2  Voltage, Material, 12V, dB, Pump, Dual, Tone, ...             7537   \n",
       "3  inch, Ankel, Leggings, Length, 30, 32, 34, col...             2996   \n",
       "5  HINS, Pot, one, choice, plants, take, color, r...             5725   \n",
       "7  br, nbsp, strong, kitchen, Aluminum, Foil, tim...             6030   \n",
       "9  oils, Transform, home, workplace, hotel, room,...             8201   \n",
       "\n",
       "   PRODUCT_LENGTH NUMERIC_DATA  \n",
       "2      748.031495               \n",
       "3      787.401574               \n",
       "5      950.000000               \n",
       "7      984.251967               \n",
       "9      393.700787               "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the dataframe\n",
    "sum_df.to_csv(\"dataset/updated_dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
